---
title: "Tornado first regression"
author: "Helen Greatrex"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: yes
    number_sections: yes
    theme: lumen
    df_print: paged
  html_notebook:
    toc: true
    toc_float: yes
    number_sections: yes
    theme: lumen   
---

# Headings

## sub-headings

### sub-sub-heading (as long as there is a SPACE after the #)

we have space for text. Click insert (top right, then R)

```{r, message=FALSE, warning=FALSE}
# load library
# if a library doesn't exist, then to download, go to the packages menu (next to help) and click install

# Upon downloading the .rmd file, I attempted to run this first code chunk and found that many of the libraries weren't installed.
#I needed to install each library before downloading it via this code

rm(list=ls())
library(sp)
library(sf)
library(raster)
library(tidycensus)
library(tidyverse)
library(plotly)
library(olsrr)
library(tmap)
library(RColorBrewer)
library("lubridate")
library(dplyr)
```

Write some more notes. Click preview to see a doc of the answer
Look at Rstudio markdown tutorial for more cool stuff

```{r}
# dot . means current folder - and you don't need a file extension

# this code chunk uses "st_read" to read in the features from the initial tornado point shapefile
# the table/spreadsheet of data is saved to a variable "T_data"
T_data <- st_read(dsn="./1950-2019-torn-initpoint",
                  layer="1950-2019-torn-initpoint")

```

To see the data, you can click on its name, or make a code chunk and type View(T_data)

We can access individual columns using the $ symbol

```{r}
# columnn names, by the way, in a code chunk, the # means don't run this line
#this command displays all of the field names within the shapefile we read in with the previous code chunk
# the other way to think about it is that it's the column names in your spreadsheet.
names(T_data)
```

```{r}

#summary gives details of each column of data within the shapefile
#some columns, date and time, are characters according to R
#we will need to convert these to a readable number in order to work with them and performa analysis

summary(T_data)
```

```{r}
# print the 1st 6  values
#the head command displays the first six values from the selected column
#in this case we see the first 6 dates in the "date" columns
#R is interpreting these as characters, rather than a date
#we will need to convert them into something that R understands is a date

head(T_data$date)
```

```{r}

#we use the head command here to give us the first 6 values for the entire data set
#additional information is provided around the metadata including geometry type, etc.

head(T_data)
```



```{r}
# we need to find the format
# we look at the help file for strptime (this is not obvious)
#?strptime
```


```{r}
# make the date
# set the values in the date column to the variable "T_data$date"
#as.Date command converts the character data in the column to represent calendar dates
#calendar date is in the format year, month, date

T_data$date <- as.Date(T_data$date, format="%Y-%m-%d")
```


```{r}
#using the summary function again, we display all the data in the shapefile
#now the date column is displaying calendar dates rather than a character

summary(T_data)

```


```{r}
# Let's cheat
head(T_data$time)

# strsplit splits each character time string into a "list" (advent calendar) of the hour, minutes and seconds for each row 
Fulltimes <- strsplit(T_data$time,":")


# Now we use the lapply function to make a new list with just the first one
# and we turn it back into just a normal row of numbers
T_data$hours   <-as.numeric(unlist(lapply(Fulltimes, "[",1)))
T_data$minutes <-as.numeric(unlist(lapply(Fulltimes, "[",2)))
T_data$seconds <-as.numeric(unlist(lapply(Fulltimes, "[",3)))
T_data$DecimalHour <- T_data$hours + (T_data$minutes/60)

```




```{r}

#using the summary function again, we display all the data in the shapefile
#now we see our new column "datetime"
#however, this is a character again
#we will need to convert this into something meaningful to analyze

summary(T_data)

```



```{r}
# This is the number of tornados at each magnitude and each hour
table(T_data$hour,T_data$mag)
```





```{r}
#using the summary function again, we display all the data in the shapefile
#now we see our new column "datetime"
#however, this is a character again
#we will need to convert this into something meaningful to analyze

summary(T_data)

```



```{r}
# I need to extract the hours and minutes from the $datetime column
#I found the code below which I think will help to get to the point where I will have the time value needed
#However, I am unsure how to match up what I see in the code below to our data

#I ran the code and it produces results but again, my confusion lies in how to translate the example code into something that works with #our data

Time <- factor("08:01:01")

# parese date
a <- hms(as.character(Time))

# get hours
hour(a)

# get minutes
minute(a)

# so overall - nice work
#a <- hms(T_data$time)
#T_data$hour <- hour(a)
#T_data$minutes <- minute(a)

```


```{r}
# the tilda ~ means y depends on x... so fatalities (y axis) depend on time (x-axis)
# ignore time for now
plot(T_data$DecimalHour,T_data$mag,cex=.2)

# ?par for more plotting parameters
# https://www.r-graph-gallery.com/
```

```{r}
# Bin size control + color palette
ggplot(T_data, aes(x=DecimalHour, y=mag) ) +
  geom_bin2d(bins = 70) +
  scale_fill_continuous(type = "viridis") +
  theme_bw()
```


# remove missing data

mag < 0 has been set to NA, as directed by https://www.spc.noaa.gov/wcm/data/SPC_severe_database_description.pdf


```{r}

#some values in the magnitude column were -9.  according to NOAA these were undetermined magnitude tornadoes, which we will remove from the data

T_data$mag[T_data$mag < 0 ] <- NA
```


```{r}
# Bin size control + color palette
ggplot(T_data, aes(x=DecimalHour, y=mag) ) +
  geom_bin2d(bins = 70) +
  scale_fill_continuous(type = "viridis") +
  theme_bw()
```


```{r}
# Bin size control + color palette
ggplot(T_data, aes(x=DecimalHour, y=fat) ) +
  geom_bin2d(bins = 70) +
  scale_fill_continuous(type = "viridis") +
  theme_bw()
```

```{r}
TimeOfDay <- split(T_data,as.factor(T_data$hours))

TimeOfDaySummary <- data.frame(TimeOfDay= unlist(lapply(split(T_data$hours,as.factor(T_data$hours)),"[",1)),
                               NumberOfTornados = unlist(lapply(TimeOfDay,nrow)),
                               TotalFatalities = unlist(lapply(split(T_data$fat,as.factor(T_data$hours)),sum,na.rm=TRUE)),
                               AvMag = unlist(lapply(split(T_data$mag,as.factor(T_data$hours)),mean,na.rm=TRUE)))

  
  

TimeOfDaySummary$AvFatPerTornado  <- TimeOfDaySummary$TotalFatalities / TimeOfDaySummary$NumberOfTornados

TimeOfDaySummary
```


```{r}
plot(TimeOfDaySummary$AvFatPerTornado ~  TimeOfDaySummary$TimeOfDay,type="o")
```

```{r}

T_data_Mag0 <- filter(T_data,mag==0)

TimeOfDay_Mag0 <- split(T_data_Mag0,as.factor(T_data_Mag0$hours))

TimeOfDaySummary_Mag0 <- data.frame(TimeOfDay        = unlist(lapply(split(T_data_Mag0$hours,as.factor(T_data_Mag0$hours)),"[",1)),
                               NumberOfTornados = unlist(lapply(TimeOfDay_Mag0,nrow)),
                               TotalFatalities  = unlist(lapply(split(T_data_Mag0$fat,as.factor(T_data_Mag0$hours)),sum,na.rm=TRUE)),
                               AvMag            = unlist(lapply(split(T_data_Mag0$mag,as.factor(T_data_Mag0$hours)),mean,na.rm=TRUE)))



TimeOfDaySummary_Mag0$AvFatPerTornado  <- TimeOfDaySummary_Mag0$TotalFatalities / TimeOfDaySummary_Mag0$NumberOfTornados

plot(TimeOfDaySummary_Mag0$TotalFatalities ~  TimeOfDaySummary_Mag0$TimeOfDay,type="o")

```

```{r}
# MAG 4
## double equals
T_data_Mag4 <- filter(T_data,mag == 4)

TimeOfDay_Mag4 <- split(T_data_Mag4,as.factor(T_data_Mag4$hours))

TimeOfDaySummary_Mag4 <- data.frame(TimeOfDay        = unlist(lapply(split(T_data_Mag4$hours,as.factor(T_data_Mag4$hours)),"[",1)),
                               NumberOfTornados = unlist(lapply(TimeOfDay_Mag4,nrow)),
                               TotalFatalities  = unlist(lapply(split(T_data_Mag4$fat,as.factor(T_data_Mag4$hours)),sum,na.rm=TRUE)),
                               AvMag            = unlist(lapply(split(T_data_Mag4$mag,as.factor(T_data_Mag4$hours)),mean,na.rm=TRUE)))



TimeOfDaySummary_Mag4$AvFatPerTornado  <- TimeOfDaySummary_Mag4$TotalFatalities / TimeOfDaySummary_Mag4$NumberOfTornados

plot(TimeOfDaySummary_Mag4$AvFatPerTornado ~  TimeOfDaySummary_Mag4$TimeOfDay,type="o")


```
TO DO: Look at the existing papers on time of day, did they scale by per tornado?  or something else?

Add in extra mags and have a look,
Start playing with other columns or making regressions..  
In words, now you have this, what's interesting, THINK SPATIALLY 
Maybe do it as a powerpoint



```{r}

TimeOfDay <- split(T_data,as.factor(T_data$hours))



```








```{r}
# the tilda ~ means y depends on x... so fatalities (y axis) depend on time (x-axis)
# ignore time for now
plot(T_data$fat ~ T_data$mag,cex=.5)
```


this tutorial will be useful in honing code
https://hgreatrex.github.io/lab-7.html#tutorial-2-regression


```{r}
#x,y

p <-  T_data %>%                  
  ggplot( aes(mag,fat,col= datetime,label=om)) +
  geom_point() +
  theme_classic()+
  scale_color_gradient(low="blue", high="red")

ggplotly(p)
```


to do a regression

```{r}
firstmodel <- lm(fat ~ mag, data=T_data)
ols_regress(firstmodel)

firstmodel
```

fatalities = mag*0.73 - 0.9098


```{r}
plot(T_data$fat ~ T_data$mag)
abline(firstmodel)
```

```{r}
T_data$FirstModel.Residuals <- residuals(firstmodel)




# subset the illinois census data with the Chicago city limits
tm_shape(T_data, unit = "mi") + 
           tm_dots(col = "FirstModel.Residuals", style = "quantile",
                       palette = "-RdBu", border.alpha = 0, 
                       title = "First model residuals")#+
 #   tm_shape(Chicago.city) +
  #         tm_borders()+
    tm_layout(legend.outside = TRUE) 
```

